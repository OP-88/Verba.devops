# ğŸ™ï¸ Verba Audio Transcription System

<div align="center">

**ğŸš€ Enhanced AI-powered audio transcription with real-time microphone recording**

[![Status](https://img.shields.io/badge/Status-âœ…_Operational-brightgreen?style=for-the-badge)](https://github.com/marc-254/Verba.devops)
[![TypeScript](https://img.shields.io/badge/TypeScript-4.9+-3178C6?style=for-the-badge&logo=typescript&logoColor=white)](https://www.typescriptlang.org/)
[![React](https://img.shields.io/badge/React-18+-61DAFB?style=for-the-badge&logo=react&logoColor=black)](https://reactjs.org/)
[![Vite](https://img.shields.io/badge/Vite-4+-646CFF?style=for-the-badge&logo=vite&logoColor=white)](https://vitejs.dev/)
[![Python](https://img.shields.io/badge/Python-3.8+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-009688?style=for-the-badge&logo=fastapi&logoColor=white)](https://fastapi.tiangolo.com/)

*Open-source â€¢ Offline-capable â€¢ Production-ready*

[ğŸš€ Quick Start](#-quick-start) â€¢ [âœ¨ Features](#-features) â€¢ [ğŸ“– Documentation](#-documentation) â€¢ [ğŸ¤ Contributing](#-contributing)

</div>

---

## ğŸŒŸ Overview

**Verba** is a cutting-edge audio transcription system that combines the power of OpenAI Whisper with modern web technologies. Designed for **students**, **professionals**, and **content creators**, it offers real-time microphone recording, intelligent content detection, and specialized processing for music and rap transcription.

> **ğŸ¯ Perfect for:** Meeting notes â€¢ Lecture transcription â€¢ Music lyrics â€¢ Podcast processing â€¢ Voice memos

### ğŸ­ What Makes Verba Special?

- **ğŸ¤ Real-time Recording** - Browser-based microphone capture with visual feedback
- **ğŸ§  Smart AI Processing** - Whisper "base" model with context-aware prompting  
- **ğŸµ Music Optimized** - Specialized handling for rap, hip-hop, and musical content
- **ğŸŒ Offline First** - No internet required, privacy-focused
- **âš¡ Modern Stack** - React + TypeScript + Vite + FastAPI

---

## âœ¨ Features

<table>
<tr>
<td width="50%">

### ğŸ¤ **Real-Time Audio**
- **Live microphone capture** via WebRTC
- **Visual audio levels** with recording timer
- **Automatic processing** when recording stops
- **Cross-browser support** (Chrome, Firefox, Safari)

</td>
<td width="50%">

### ğŸš€ **Enhanced AI Transcription** 
- **OpenAI Whisper "base"** model (upgraded accuracy)
- **Smart content detection** (Speech vs Music)
- **Context-aware prompting** for specialized content
- **90+ languages** supported natively

</td>
</tr>
<tr>
<td>

### ğŸ’ **Modern Interface**
- **Glassmorphism UI** with beautiful gradients
- **Responsive design** across all devices
- **Mode switching** (microphone vs file upload)
- **Enhanced history** with metadata badges

</td>
<td>

### ğŸ“Š **Advanced Backend**
- **FastAPI** with automatic documentation
- **SQLite** with connection pooling
- **Processing metrics** tracking
- **Content classification** system

</td>
</tr>
</table>

---

## ğŸš€ Quick Start

### ğŸ“‹ Prerequisites

```bash
Node.js 16+    # Frontend development
Python 3.8+    # Backend processing  
4GB+ RAM       # For Whisper base model
```

### âš¡ Installation

**1ï¸âƒ£ Clone Repository**
```bash
git clone https://github.com/marc-254/Verba.devops.git
cd Verba.devops
```

**2ï¸âƒ£ Backend Setup**
```bash
cd backend
pip install -r requirements.txt

# Start backend server
uvicorn main:app --host 0.0.0.0 --port 8000
```

**3ï¸âƒ£ Frontend Setup**
```bash
cd verba-frontend-ts
npm install

# Start development server
npm run dev
```

**4ï¸âƒ£ Launch Application**
```bash
# ğŸŒ Frontend: http://localhost:5173
# ğŸ“‹ API Docs: http://localhost:8000/docs
# âœ… Health Check: http://localhost:8000/health
```

### ğŸ¯ First Steps

<table>
<tr>
<th>ğŸ¤ Microphone Mode</th>
<th>ğŸ“ File Upload Mode</th>
</tr>
<tr>
<td>
<ol>
<li>Click <strong>"ğŸ¤ Microphone"</strong> tab</li>
<li>Allow browser permissions</li>
<li>Hit <strong>"Start Recording"</strong></li>
<li>Speak clearly for 5-30 seconds</li>
<li>Click <strong>"Stop Recording"</strong></li>
<li>Watch AI transcription magic! âœ¨</li>
</ol>
</td>
<td>
<ol>
<li>Switch to <strong>"ğŸ“ Upload File"</strong></li>
<li>Select audio (MP3/WAV/M4A)</li>
<li>Monitor processing progress</li>
<li>Review content type detection</li>
<li>Check transcription accuracy</li>
<li>View enhanced metadata ğŸ“Š</li>
</ol>
</td>
</tr>
</table>

---

## ğŸ—ï¸ Architecture

### ğŸ› ï¸ Technology Stack

```mermaid
graph TB
    A[ğŸ¤ WebRTC Audio] --> B[React + TypeScript]
    B --> C[Vite Build System]
    C --> D[FastAPI Backend]
    D --> E[OpenAI Whisper]
    E --> F[SQLite Database]
    
    style A fill:#e1f5fe
    style B fill:#f3e5f5
    style C fill:#e8f5e8
    style D fill:#fff3e0
    style E fill:#fce4ec
    style F fill:#f1f8e9
```

### ğŸ“ Project Structure

```
verba-audio-transcription/
â”œâ”€â”€ ğŸ¯ backend/
â”‚   â”œâ”€â”€ main.py                    # ğŸš€ Enhanced FastAPI server
â”‚   â”œâ”€â”€ requirements.txt           # ğŸ“¦ Python dependencies
â”‚   â””â”€â”€ verba_app.db              # ğŸ—„ï¸ SQLite database
â”‚
â”œâ”€â”€ ğŸ’» verba-frontend-ts/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ MicrophoneRecorder.tsx      # ğŸ¤ Real-time recording
â”‚   â”‚   â”‚   â”œâ”€â”€ AudioUploader.tsx           # ğŸ“ File upload
â”‚   â”‚   â”‚   â”œâ”€â”€ TranscriptionDisplay.tsx    # ğŸ“ Results display
â”‚   â”‚   â”‚   â””â”€â”€ TranscriptionHistory.tsx    # ğŸ“š History + metadata
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ services/api.ts                 # ğŸ”Œ API integration
â”‚   â”‚   â”œâ”€â”€ types/api.ts                    # ğŸ“ TypeScript interfaces
â”‚   â”‚   â””â”€â”€ App.tsx                         # ğŸ¯ Main application
â”‚   â”‚
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.ts
â”‚
â””â”€â”€ ğŸ“– docs/
    â””â”€â”€ API_REFERENCE.md
```

---

## ğŸ”§ API Reference

### ğŸ¥ Health Check
```http
GET /health
```
**Response:**
```json
{
  "status": "healthy",
  "model": "loaded", 
  "model_size": "base",
  "enhanced_features": true,
  "librosa_available": true
}
```

### ğŸµ Transcribe Audio
```http
POST /transcribe
Content-Type: multipart/form-data

audio: <audio_file>
```
**Features:**
- âœ… Smart content detection (Music vs Speech)
- âœ… Context-aware processing for rap/hip-hop
- âœ… Enhanced metadata extraction
- âœ… Processing time tracking

### ğŸ“š Get Transcription History  
```http
GET /transcriptions?session_id=default
```
**Returns:** Array with enhanced metadata including content type, processing metrics, and model version.

---

## ğŸ› Troubleshooting

<details>
<summary><strong>ğŸš¨ Common Issues & Solutions</strong></summary>

### Issue: 422 Unprocessable Content Error
**Root Cause:** Missing `session_id` parameter in API calls

**âœ… Solution:**
```typescript
// Update services/api.ts
const response = await fetch(`${API_BASE_URL}/transcriptions?session_id=default`);
```

### Issue: Microphone Not Working
**Possible Causes:** Browser permissions, HTTPS requirement

**âœ… Solutions:**
- Allow microphone access in browser settings
- Use HTTPS in production (HTTP works on localhost)
- Check browser compatibility: Chrome 53+, Firefox 36+, Safari 11+

### Issue: Vite Build Errors
**Common TypeScript/React Issues:**

```bash
# Clear cache and reinstall
rm -rf node_modules package-lock.json
npm install

# Force Vite rebuild
npm run dev -- --force

# Update TypeScript
npm install typescript@latest
```

### Issue: Python Dependencies 
**Whisper Installation Problems:**

```bash
# For Apple Silicon Macs
pip install torch torchaudio

# For CUDA support  
pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu118

# Alternative Whisper install
pip install openai-whisper --upgrade
```

</details>

---

## ğŸ“Š Performance & Specifications

### ğŸ¯ Model Performance
- **Processing Speed:** ~2-3x real-time
- **Model Size:** Whisper Base (~140MB, 39M parameters)  
- **Accuracy:** Significant improvement over tiny model
- **Memory Usage:** ~1GB RAM recommended
- **Languages:** 90+ supported natively

### ğŸ’» System Requirements
| Component | Minimum | Recommended |
|-----------|---------|-------------|
| **RAM** | 4GB | 8GB |
| **Storage** | 2GB free | 5GB free |
| **OS** | Windows 10, macOS 10.15, Ubuntu 18.04 | Latest versions |
| **Browser** | Chrome 53+, Firefox 36+, Safari 11+ | Latest Chrome |

### âš¡ Optimization Tips
- Use **base model** for best accuracy/speed balance
- Enable **voice activity detection** for long recordings
- Consider **chunking audio** files over 10 minutes
- Monitor **memory usage** during batch processing

---

## ğŸ¤ Contributing

We welcome contributions from the community! Here's how to get involved:

### ğŸ¯ Development Setup
```bash
# Backend development mode
cd backend
uvicorn main:app --reload

# Frontend development mode  
cd verba-frontend-ts
npm run dev -- --host
```

### ğŸ“‹ Contribution Process
1. **ğŸ´ Fork** the repository
2. **ğŸŒ¿ Create** a feature branch (`git checkout -b feature/amazing-feature`)
3. **ğŸ’¾ Commit** your changes (`git commit -m 'Add amazing feature'`)
4. **ğŸš€ Push** to branch (`git push origin feature/amazing-feature`)  
5. **ğŸ¯ Open** a Pull Request

### ğŸ¨ Areas We Need Help
- [ ] **Real-time streaming** transcription
- [ ] **Language detection** automation
- [ ] **Speaker diarization** features
- [ ] **Export functionality** (PDF, DOCX)
- [ ] **Mobile app** development
- [ ] **Documentation** improvements

---

## ğŸ“„ License & Credits

### ğŸ“‹ License
This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for full details.

### ğŸ™ Acknowledgments
- **[OpenAI Whisper](https://github.com/openai/whisper)** - Robust speech recognition model
- **[FastAPI](https://fastapi.tiangolo.com/)** - Modern Python web framework  
- **[Vite](https://vitejs.dev/)** - Next generation frontend tooling
- **[React](https://reactjs.org/)** - User interface library
- **Original Verba Project** - Foundation and inspiration

### ğŸ‘¨â€ğŸ’» Developed By
**Mark Munene** - *Full-stack Developer & AI Enthusiast*

---

## ğŸ“ Support & Community

<div align="center">

### ğŸ’¬ Get Help & Connect

[![GitHub Issues](https://img.shields.io/badge/Issues-GitHub-red?style=for-the-badge&logo=github)](https://github.com/marc-254/Verba.devops/issues)
[![Discussions](https://img.shields.io/badge/Discussions-GitHub-blue?style=for-the-badge&logo=github)](https://github.com/marc-254/Verba.devops/discussions)  
[![Documentation](https://img.shields.io/badge/Docs-Available-green?style=for-the-badge&logo=gitbook)](./docs/)

**Found a bug?** Open an issue â€¢ **Need help?** Start a discussion â€¢ **Want to contribute?** Check our guidelines

---

### ğŸŒŸ Show Your Support

**If Verba helps you, please consider:**

â­ **Star** this repository â€¢ ğŸ› **Report** bugs â€¢ ğŸ’¡ **Suggest** features â€¢ ğŸ¤ **Contribute** code

**Built with â¤ï¸ for seamless audio transcription**

*Last updated: August 28, 2025*

</div>
